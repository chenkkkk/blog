## 第一章 绪论

机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。如果说计算机科学是研究关于`算法`的学问，那么可以说机器学习是研究关于`学习算法`的学问

若预测的是离散值，例如好瓜、坏瓜，此类学习任务称为`分类`；若预测的是连续值，例如西瓜的成熟度0.95、0.37，此类学习任务称为`回归`。一般地，预测任务是希望通过对训练集![equation](http://latex.codecogs.com/gif.latex?\lbrace(x_1,y_1),(x_2,y_2),...,(x_m,Y_m)\rbrace)进行学习，建立一个从输入空间![equation](http://latex.codecogs.com/gif.latex?\chi)到输出空间![equation](http://latex.codecogs.com/gif.latex?y)的映射![equation](http://latex.codecogs.com/gif.latex?\chi)。对二分任务，通常令![equation](http://latex.codecogs.com/gif.latex?y=\lbrace-1,1\rbrace)或![equation](http://latex.codecogs.com/gif.latex?y=\lbrace0,1\rbrace)；对多分类任务，![equation](http://latex.codecogs.com/gif.latex?|y|>2)；对回归任务，![equation](http://latex.codecogs.com/gif.latex?y=R)，R为实数集

根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：监督学习和无监督学习，分类和回归是前者的代表，而聚类则是后者的代表

通常假设样本空间中全体样本服从一个未知的`分布`![equation](http://latex.codecogs.com/gif.latex?D)，我们获得的每个样本都是独立地从这个分布上采样获得的，即`独立同分布`。一般而言，训练样本越多，得到的关于![equation](http://latex.codecogs.com/gif.latex?D)的信息越多，这样就越有可能通过学习获得具有强

## 第二章 模型评估与选择

通常把分类错误的样本数占样本总数的比例称为`错误率（error rate）`,即如果在m个样本中有a个样本分类错误，则错误率![equation](http://latex.codecogs.com/gif.latex?E=a/m) 

![equation](http://latex.codecogs.com/gif.latex?1-a/m)称为精度(accuracy)

交叉验证法(cross validation)

调参(parameter tuning)

回归任务最常用的性能度量是`均方误差`(mean squared error)

![equation](http://latex.codecogs.com/gif.latex?E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_i)-y_i)^2) 

查准率(precision)、查全率(recall)与F1
挑出的西瓜中有多少比例是好瓜、所有好瓜中有多少比例被挑了出来

## 第三章 线性模型

给定由d个属性描述的示例![equation](http://latex.codecogs.com/gif.latex?x=(x_1,x_2,...,x_d))，![equation](http://latex.codecogs.com/gif.latex?x_i)![equation](http://latex.codecogs.com/gif.latex?x)在![equation](http://latex.codecogs.com/gif.latex?i)个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即

![equation](http://latex.codecogs.com/gif.latex?f(x)=w_1x_1+w_2x_2+...+w_dx_d+b)

![equation](http://latex.codecogs.com/gif.latex?f(x)=w^Tx+b) 

如何确定w和b，可试图让均方误差最小化，即![equation](http://latex.codecogs.com/gif.latex?(w^*,b^*)=argmin_{(w,b)}\sum_{i=1}^m(f(x_i)-y_i)^2) 

均方误差对应了常用的欧几里得距离或简称欧式距离，基于均方误差最小化来进行模型求解的方法称为`最小二乘法`，求解w和b使上式最小化的过程，称为线性回归模型的最小二乘参数估计

线性判别分析(Linear Discriminant Analysis，简称LDA)，是一种经典的线性学习方法，给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近，异类样例的投影点尽可能远离

## 第四章 决策树


